{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5003678-94ec-4940-b0b4-cc3f6a60425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import integrate\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/dteng/Documents/bin/nmr_utils/\")\n",
    "from nmr_targeted_utils import *\n",
    "from nmr_fitting_funcs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a66d57-ad08-4055-a1a7-dbc5b598cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results folder = ./results/mlgrad_fitting-lproline_ph3-20240429_1116\n",
      "Loaded 128 samples.\n"
     ]
    }
   ],
   "source": [
    "# ===== params =====\n",
    "template_path = \"/Users/dteng/Documents/zdata/nmr/nmr_std_data/indiv_std_lproline/lproline_ph3.csv\"\n",
    "path_samples = \"/Users/dteng/Documents/zdata/nmr/J202208B_pro_survey/training_set_csvs/\"\n",
    "bs_grad_path = \"/Users/dteng/Documents/nmr_targeted/mlgrad/results/bootstrap_results.csv\"\n",
    "matching_path = \"/Users/dteng/Documents/zdata/nmr/nmr_std_data/lr_matching_coords/lproline_ph3_matching_regions.csv\"\n",
    "\n",
    "# diff mcoords for neat-pro-std or pro_std_03\n",
    "if \"pro_std_03\" in template_path:\n",
    "    multiplets_ls = [[1.9,2.15], [2.304, 2.408],[3.25, 3.5],[4.1, 4.2]]\n",
    "if \"lproline_ph3\" in template_path:\n",
    "    multiplets_ls = [[1.9,2.15], [2.295, 2.403], [3.25, 3.5],[4.1, 4.2]]\n",
    "\n",
    "normxcorr_th = 0.0 # set to this number to filter out multiplets which aren't at least normxcorr_th, i.e. poor fits\n",
    "ref_pk_window = [-0.2, 0.2]\n",
    "ref_pk_tolerance_window = [0,0]\n",
    "search_region_padding_size = 0.02\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "folder_name = f\"./results/mlgrad_fitting-{template_path.split('/')[-1].replace('.csv', '')}-{timestamp}\"\n",
    "fn_out_plot = \"training_fit_viz.html\"\n",
    "\n",
    "print(f\"results folder = {folder_name}\")\n",
    "\n",
    "# ========== load data ==========\n",
    "# load STD template(s)\n",
    "template_df = pd.read_csv(template_path)\n",
    "template_df = adjust_to_ref_peak(template_df, ref_pk_window, ref_pk_tolerance_window)\n",
    "\n",
    "# load sample (training) data - only QCs and Rs\n",
    "df_dict = {}\n",
    "for fn in os.listdir(path_samples):\n",
    "    if \".csv\" in fn:\n",
    "        k = fn.split(\".\")[0].replace(\"_QC\", \"_Q\")\n",
    "        df_dict[k] = pd.read_csv(os.path.join(path_samples, fn))\n",
    "print(f\"Loaded {len(df_dict)} samples.\")\n",
    "\n",
    "matching_regions_ls = [\n",
    "    [2.305, 2.306],\n",
    "    [2.31, 2.316],\n",
    "    [2.321, 2.3225],\n",
    "    [2.331, 2.333],\n",
    "    [2.337, 2.339],\n",
    "    [2.342, 2.3445],\n",
    "    [2.347, 2.349],\n",
    "    [2.3585, 2.3605],\n",
    "    [2.365, 2.3675],\n",
    "    [2.3755, 2.3765],\n",
    "    [2.381, 2.39]]\n",
    "\n",
    "matching_regions_ls2 = [\n",
    "    [2.3, 2.4]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e44271-5be6-47a9-96aa-402596c14fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n"
     ]
    }
   ],
   "source": [
    "# ===== run 1d_std_search =====\n",
    "results_dict = {}\n",
    "for k in sorted(list(df_dict.keys())):\n",
    "    target_df = df_dict[k]\n",
    "    results_dict[k] = do_1d_std_search(\n",
    "        query_df=template_df,\n",
    "        target_df=target_df,\n",
    "        multiplets_ls=multiplets_ls,\n",
    "        search_region_padding_size=search_region_padding_size\n",
    "    )\n",
    "\n",
    "# get reds\n",
    "red_dt = template_df.copy()\n",
    "red_dt = red_dt.loc[(red_dt[\"ppm\"]>min(multiplets_ls[1])) & (red_dt[\"ppm\"]<max(multiplets_ls[1]))]\n",
    "\n",
    "# get blues\n",
    "blue_m1_dict = get_blue_m1_dict(results_dict, \n",
    "                                df_dict,\n",
    "                                mcoords=multiplets_ls[1]\n",
    "                               )\n",
    "\n",
    "# ===== get corr_series_dict =====\n",
    "# get corr_series for each k, stored in corr_series_dict\n",
    "corr_series_dict = {}\n",
    "for k in sorted(list(results_dict.keys())):\n",
    "    dt = get_correlation_series(red_dt, \n",
    "                                blue_m1_dict[k].copy(),\n",
    "                                min_corr=0, \n",
    "                                min_corr_replacement_value=0,\n",
    "                                window_size_nrows=64,\n",
    "                                exponent=8\n",
    "                               )\n",
    "    corr_series_dict[k] = dt\n",
    "\n",
    "# ===== run LR matching =====\n",
    "df_conc = get_df_conc_lrmatching(\n",
    "    results_dict=results_dict, \n",
    "    template_df=template_df.copy(), \n",
    "    df_dict=df_dict, \n",
    "    mcoords=multiplets_ls[1],\n",
    "    matching_coords_ls=matching_regions_ls,\n",
    "    corr_series_dict=corr_series_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408b3952-ed14-4b23-88e0-cbd65646b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sample_names_ls = [\"AF61396_R2\", \"AF60343_Q2\", \"AF63540_R1\"]\n",
    "# do LR without specified matching regions\n",
    "selected_lr_dict = {}\n",
    "for k in selected_sample_names_ls:\n",
    "    blue_dt = blue_m1_dict[k].copy()\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(red_dt.intensity.values.reshape(-1, 1), \n",
    "              blue_dt.intensity.values\n",
    "              )\n",
    "\n",
    "    subdict = {\"intercept\":model.intercept_, \n",
    "              \"slope\":model.coef_[0]}\n",
    "    selected_lr_dict[k] = subdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf390b0c-315b-4d20-9fc0-d8c0055672a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===== plot match results =====\n",
    "fig, ax = plt.subplots(nrows=2,\n",
    "                       ncols=len(selected_sample_names_ls), \n",
    "                       figsize=(30, 10)\n",
    "                      )\n",
    "\n",
    "mcoords_xl = [\n",
    "    min(multiplets_ls[1]) - search_region_padding_size, \n",
    "    max(multiplets_ls[1]) + search_region_padding_size, \n",
    "]\n",
    "\n",
    "# plot fit\n",
    "for i in range(len(selected_sample_names_ls)):\n",
    "    k = selected_sample_names_ls[i]\n",
    "    \n",
    "    # ===== plot \"before\" =====\n",
    "    # get LR params\n",
    "    m0 = selected_lr_dict[k][\"slope\"]\n",
    "    c0 = selected_lr_dict[k][\"intercept\"]\n",
    "    blue_dt = blue_m1_dict[k].copy()\n",
    "\n",
    "    # plot!\n",
    "    ax[0, i].plot(red_dt.ppm.values, \n",
    "                  (red_dt.intensity.values*m0)+c0, \n",
    "                  c=\"indianred\"\n",
    "                 )\n",
    "    ax[0, i].plot(blue_dt.ppm.values, \n",
    "                  blue_dt.intensity.values,\n",
    "                  c=\"steelblue\"\n",
    "                 )\n",
    "\n",
    "    #ax[1, i].set_title(f\"{k}\\nnormxcorr={round(normxcorr, 4)}\", fontsize=20)\n",
    "    \n",
    "    # ===== plot \"after\" =====\n",
    "    normxcorr = results_dict[k][\"multiplet_1\"][\"max_rho\"][0]\n",
    "    ax[1, i].plot(blue_m1_dict[k].ppm.values, \n",
    "            blue_m1_dict[k].intensity.values, c=\"steelblue\")\n",
    "    \n",
    "    m = df_conc.loc[df_conc[\"sample_name\"]==k][\"slope\"].values[0]\n",
    "    c = df_conc.loc[df_conc[\"sample_name\"]==k][\"intercept\"].values[0]\n",
    "    ax[1, i].plot(red_dt.ppm.values, \n",
    "            (red_dt.intensity.values*m)+c, \n",
    "            c=\"indianred\")\n",
    "    \n",
    "    # plot sliding window of correlation\n",
    "    ax2 = ax[1, i].twinx()\n",
    "    ax2.plot(corr_series_dict[k][\"ppm\"], \n",
    "             corr_series_dict[k][\"corr_series\"], \n",
    "             lw=0.7,\n",
    "             c=\"k\")\n",
    "    \n",
    "    # set bg colour\n",
    "    transparency = 0.65\n",
    "    bg_colour = (1, 159/255, 165/255, transparency) # red\n",
    "    if normxcorr >= 0.85 and normxcorr < 0.9:\n",
    "        bg_colour = (1, 184/255, 100/255, transparency) # orange\n",
    "    if normxcorr >= 0.9 and normxcorr < 0.95:\n",
    "        bg_colour = (1, 242/255, 100/255, transparency) # yellow     \n",
    "    if normxcorr >= 0.95 and normxcorr < 0.99:\n",
    "        bg_colour = (150/255, 1, 153/255, transparency) # green\n",
    "    elif normxcorr >= 0.99:\n",
    "        bg_colour = (140/255, 220/255, 1, transparency) # light blue\n",
    "    # ax[1, i].set_facecolor(bg_colour)\n",
    "    # plt.setp(ax[1, i].get_xticklabels(), fontsize=20)\n",
    "    # plt.setp(ax[1, i].get_yticklabels(), fontsize=20)\n",
    "    \n",
    "    # draw matching regions\n",
    "    rect_height = ax[1, i].get_ylim()[1]\n",
    "    for row in matching_regions_ls:\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((min(row), 0), \n",
    "                                 max(row) - min(row), \n",
    "                                 rect_height, \n",
    "                                 edgecolor=None,\n",
    "                                 facecolor='grey', \n",
    "                                 alpha=0.25)\n",
    "    \n",
    "        # Add the rectangle patch to the plot\n",
    "        ax[1, i].add_patch(rect)\n",
    "\n",
    "    # final bits\n",
    "    ax[0, i].set_xlim([max(mcoords_xl), min(mcoords_xl)])\n",
    "    ax[1, i].set_xlim([max(mcoords_xl), min(mcoords_xl)])\n",
    "    ax[0, i].set_title(k, fontsize=30)\n",
    "    ax[0, 0].set_ylabel(f\"Before\", fontsize=30)\n",
    "    ax[1, 0].set_ylabel(f\"After\", fontsize=30)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.savefig(f\"./figs/before_n_after.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c11090-f2b6-4899-864b-c0487565c700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
