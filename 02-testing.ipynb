{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "* Given a learnt gradient, predict value of conc in samples. \n",
    "* Run in batches of size 100 so that not all 1000+ samples are loaded into memory all at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import integrate\n",
    "\n",
    "import sys\n",
    "from nmr_targeted_utils import *\n",
    "from nmr_fitting_funcs import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Data isn't loaded all at one shot, because that's just inviting out-of-memory error for very large datasets, but loaded (in the next section) and processed in batches of size `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results to be stored in ./results/test-20241226_1200\n",
      "Loaded 5000 bootstrapped gradients\n",
      "1123 samples loaded into 12 batches of size:\n",
      "1. 100\n",
      "2. 100\n",
      "3. 100\n",
      "4. 100\n",
      "5. 100\n",
      "6. 100\n",
      "7. 100\n",
      "8. 100\n",
      "9. 100\n",
      "10. 100\n",
      "11. 100\n",
      "12. 23\n",
      "Results to be stored in ./results/test-20241226_1200 (not yet created)\n"
     ]
    }
   ],
   "source": [
    "# ========== define params ==========\n",
    "load_dotenv()\n",
    "# define paths\n",
    "path_samples = os.getenv(\"TEST_PATH\")\n",
    "template_path = \"./assets/lproline_ph3.csv\"\n",
    "bs_grad_path = \"bootstrap_results_12sep2023.csv\"\n",
    "\n",
    "# proline multiplet coords\n",
    "multiplets_ls = [[1.9,2.15], [2.295, 2.403], [3.25, 3.5],[4.1, 4.2]]\n",
    "\n",
    "#signal_free_coords = [-1, 10] # signal free region is outside of these coords\n",
    "normxcorr_th = 0.0 # set to this number to filter out multiplets which aren't at least normxcorr_th, i.e. poor fits\n",
    "ref_pk_window = [-0.2, 0.2]\n",
    "ref_pk_tolerance_window = [0,0]\n",
    "search_region_padding_size = 0.02\n",
    "batch_size = 100\n",
    "\n",
    "suffix = template_path.split(\"/\")[-1].replace(\".csv\", \"\")\n",
    "fn_out_plot = f\"mlgrad_{suffix}.html\"\n",
    "fn_out_df = f\"mlgrad_{suffix}.csv\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "folder_name = f\"./results/test-{timestamp}\"\n",
    "print(f\"Results to be stored in {folder_name}\")\n",
    "\n",
    "# ========== load data ==========\n",
    "# load STD template(s)\n",
    "template_df = pd.read_csv(template_path)\n",
    "template_df = adjust_to_ref_peak(template_df, ref_pk_window, ref_pk_tolerance_window)\n",
    "\n",
    "# load bootstrap gradients\n",
    "d_bs_grad = pd.read_csv(bs_grad_path)\n",
    "print(f\"Loaded {len(d_bs_grad)} bootstrapped gradients\")\n",
    "\n",
    "matching_regions_ls = [\n",
    "    [2.305, 2.306],\n",
    "    [2.31, 2.316],\n",
    "    [2.321, 2.3225],\n",
    "    [2.331, 2.333],\n",
    "    [2.342, 2.3445],\n",
    "    [2.347, 2.349],\n",
    "    [2.3585, 2.3605],\n",
    "    [2.365, 2.3675],\n",
    "    [2.3755, 2.3765],\n",
    "    [2.381, 2.39]]\n",
    "\n",
    "# load data filenames to batch up\n",
    "fn_ls = []\n",
    "for fn in os.listdir(path_samples):\n",
    "    if \".csv\" in fn:\n",
    "        fn_ls.append(fn)\n",
    "fn_ls = sorted(fn_ls)\n",
    "\n",
    "batches_ls = [fn_ls[i:i+batch_size] for i in range(0, len(fn_ls), batch_size)]\n",
    "\n",
    "counter = 1\n",
    "print(f\"{len(fn_ls)} samples loaded into {len(batches_ls)} batches of size:\")\n",
    "for batch in batches_ls:\n",
    "    print(f\"{counter}. {len(batch)}\")\n",
    "    counter += 1\n",
    "\n",
    "# display output folder, but don't create it yet\n",
    "print(f\"Results to be stored in {folder_name} (not yet created)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder ./results/test-20241226_1200\n",
      "Processing batch 1 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n",
      "normxcorr for AF43588 too low (0.6987968375896702), returning -1 instead\n",
      "normxcorr for AF60975 too low (0.48381327436568217), returning -1 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n",
      "normxcorr for AF63412_R1 too low (0.5223211498603312), returning -1 instead\n",
      "normxcorr for AF63412_R2 too low (0.5219120503667406), returning -1 instead\n",
      "normxcorr for AF63412_Reacquire too low (0.4747896060903554), returning -1 instead\n",
      "normxcorr for AF63414 too low (0.5839849987734096), returning -1 instead\n",
      "normxcorr for AF63414_Reacquire too low (0.5487009060064658), returning -1 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n",
      "normxcorr for AW14 too low (0.6496435173465187), returning -1 instead\n",
      "normxcorr for AW14_Reacquire too low (0.6891859794259104), returning -1 instead\n",
      "normxcorr for AW2 too low (0.6039659568377201), returning -1 instead\n",
      "normxcorr for AW2_Reacquire too low (0.6093084741054559), returning -1 instead\n",
      "normxcorr for AW3 too low (0.7147880378859715), returning -1 instead\n",
      "normxcorr for AW5 too low (0.7300032283081915), returning -1 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n",
      "normxcorr for AWAC18 too low (0.6720805898414194), returning -1 instead\n",
      "normxcorr for AWAC21 too low (0.6305680557276974), returning -1 instead\n",
      "normxcorr for AWAC213 too low (0.7040251528783783), returning -1 instead\n",
      "normxcorr for AWAC213_Reacquire too low (0.7395649834906772), returning -1 instead\n",
      "normxcorr for AWAC220 too low (0.7016248027521271), returning -1 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 9 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n",
      "normxcorr for AWAC23 too low (0.6512571793109716), returning -1 instead\n",
      "normxcorr for AWAC29 too low (0.739493725814289), returning -1 instead\n",
      "normxcorr for AWAC65 too low (0.6712017219834181), returning -1 instead\n",
      "normxcorr for AWAC84 too low (0.7240515652706814), returning -1 instead\n",
      "normxcorr for AWAC85 too low (0.5723158441123795), returning -1 instead\n",
      "normxcorr for AWAC86 too low (0.6247484103035359), returning -1 instead\n",
      "normxcorr for AWAC87 too low (0.4940944337562982), returning -1 instead\n",
      "normxcorr for AWAC89 too low (0.6363099233970098), returning -1 instead\n",
      "normxcorr for AWAC90 too low (0.6371015166749969), returning -1 instead\n",
      "normxcorr for AWAC91 too low (0.7279006438998353), returning -1 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 10 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n",
      "normxcorr for FW2 too low (0.6263483234496884), returning -1 instead\n",
      "normxcorr for FW2_Reacquire too low (0.6861093407521064), returning -1 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 11 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n",
      "normxcorr for ST174 too low (0.7025507595795701), returning -1 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 12 of 12\n",
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n",
      "normxcorr for ST580 too low (0.5393416053496737), returning -1 instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 457.16s\n"
     ]
    }
   ],
   "source": [
    "# make folder\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(f\"Created folder {folder_name}\")\n",
    "\n",
    "# plot params\n",
    "ticklabel_fontsize = 10\n",
    "\n",
    "# create to store slopes and intercepts\n",
    "d_lr_results_ls = []\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "# get reds\n",
    "red_dt = template_df.copy()\n",
    "red_dt = red_dt.loc[(red_dt[\"ppm\"]>min(multiplets_ls[1])) & (red_dt[\"ppm\"]<max(multiplets_ls[1]))]\n",
    "\n",
    "blue_m1_dict_ls = []\n",
    "d_rho_ls = []\n",
    "batch_num = 1\n",
    "for batch in batches_ls:\n",
    "    print(f\"Processing batch {batch_num} of {len(batches_ls)}\")\n",
    "    # ===== load batch data =====\n",
    "    df_dict = {}\n",
    "    for fn in batch:\n",
    "        dt = pd.read_csv(os.path.join(path_samples, fn))\n",
    "        df_dict[fn.replace(\".csv\", \"\")] = adjust_to_ref_peak(\n",
    "            dt, \n",
    "            ref_coords=ref_pk_window\n",
    "        )\n",
    "\n",
    "    # ===== run 1d_std_search =====\n",
    "    results_dict = {}\n",
    "    for k in sorted(list(df_dict.keys())):\n",
    "        target_df = df_dict[k]\n",
    "        results_dict[k] = do_1d_std_search(\n",
    "            query_df=template_df,\n",
    "            target_df=target_df,\n",
    "            multiplets_ls=multiplets_ls,\n",
    "            search_region_padding_size=search_region_padding_size\n",
    "        )\n",
    "\n",
    "    # get blues\n",
    "    blue_m1_dict = get_blue_m1_dict(results_dict, \n",
    "                                    df_dict,\n",
    "                                    mcoords=multiplets_ls[1]\n",
    "                                   )\n",
    "    blue_m1_dict_ls.append(blue_m1_dict)\n",
    "\n",
    "    # ===== get corr_series_dict =====\n",
    "    # get corr_series for each k, stored in corr_series_dict\n",
    "    corr_series_dict = {}\n",
    "    for k in sorted(list(results_dict.keys())):\n",
    "        dt = get_correlation_series(red_dt, \n",
    "                                    blue_m1_dict[k].copy(),\n",
    "                                    min_corr=0, \n",
    "                                    min_corr_replacement_value=0,\n",
    "                                    window_size_nrows=64,\n",
    "                                    exponent=8\n",
    "                                   )\n",
    "        corr_series_dict[k] = dt\n",
    "\n",
    "    # ===== run LR matching =====\n",
    "    df_conc = get_df_conc_lrmatching(\n",
    "        results_dict=results_dict, \n",
    "        template_df=template_df.copy(), \n",
    "        df_dict=df_dict, \n",
    "        mcoords=multiplets_ls[1],\n",
    "        matching_coords_ls=matching_regions_ls,\n",
    "        corr_series_dict=corr_series_dict\n",
    "    )\n",
    "    \n",
    "    d_lr_results_ls.append(df_conc)\n",
    "    \n",
    "    # ===== get conc_pred =====\n",
    "    # get AUCs multiplied by all bootstrapped gradients in a matrix\n",
    "    # get conc_pred\n",
    "    auc_m = np.matmul(df_conc[\"auc\"].values.reshape(-1, 1), \n",
    "                      d_bs_grad.values.reshape(1, -1))\n",
    "\n",
    "    # get ave +/- 95% CI\n",
    "    c = []\n",
    "    for i in range(len(auc_m)):\n",
    "        ave = np.average(auc_m[i])\n",
    "        std = np.std(auc_m[i], ddof=1)\n",
    "        ci_lower = np.percentile(auc_m[i], 2.5)\n",
    "        ci_upper = np.percentile(auc_m[i], 97.5)\n",
    "        c.append([df_conc[\"sample_name\"].values[i], ave, std, ci_lower, ci_upper])\n",
    "\n",
    "    d_concpred = pd.DataFrame(data=c, \n",
    "                              columns=[\"sample_name\", \n",
    "                                       \"conc_pred_ave\", \n",
    "                                       \"conc_pred_sd\", \n",
    "                                       \"95_ci_lower\", \n",
    "                                       \"95_ci_upper\"]\n",
    "                             )\n",
    "    \n",
    "    # ===== get normxcorrs =====\n",
    "    c = []\n",
    "    for k in sorted(list(results_dict.keys())):\n",
    "        max_rho = results_dict[k][\"multiplet_1\"][\"max_rho\"][0]\n",
    "        c.append([k, max_rho])\n",
    "    d_max_rho = pd.DataFrame(data=c, columns=[\"sample_name\", \"normxcorr\"])\n",
    "    \n",
    "    d_concpred = pd.merge(d_concpred, d_max_rho, on=\"sample_name\")\n",
    "    d_rho_ls.append(d_concpred[[\"sample_name\", \"normxcorr\"]])\n",
    "    \n",
    "    # ===== plot match results =====\n",
    "    fig, ax = plt.subplots(nrows=len(results_dict), # top row for LR results\n",
    "                           ncols=1, \n",
    "                           figsize=(5, len(results_dict)*3)\n",
    "                          )\n",
    "\n",
    "    red_dt = template_df.copy()\n",
    "    red_dt = red_dt.loc[(red_dt[\"ppm\"]>min(multiplets_ls[1])) & (red_dt[\"ppm\"]<max(multiplets_ls[1]))]\n",
    "\n",
    "    i = 0\n",
    "    for k in sorted(list(results_dict.keys())):\n",
    "        # plot fit\n",
    "        normxcorr = results_dict[k][\"multiplet_1\"][\"max_rho\"][0]\n",
    "        ax[i].plot(blue_m1_dict[k].ppm.values, \n",
    "                   blue_m1_dict[k].intensity.values, c=\"steelblue\")\n",
    "\n",
    "        m = df_conc.loc[df_conc[\"sample_name\"]==k][\"slope\"].values[0]\n",
    "        c = df_conc.loc[df_conc[\"sample_name\"]==k][\"intercept\"].values[0]\n",
    "        ax[i].plot(red_dt.ppm.values, \n",
    "                   (red_dt.intensity.values*m)+c, \n",
    "                   c=\"indianred\")\n",
    "\n",
    "        ax[i].set_title(f\"{i+1}. {k}\\nnormxcorr={round(normxcorr, 4)}\")\n",
    "        \n",
    "        ax[i].plot(corr_series_dict[k][\"ppm\"].values, \n",
    "                   corr_series_dict[k][\"corr_series\"].values,\n",
    "                   ls=\"--\",\n",
    "                   lw=0.5,\n",
    "                   c=\"k\"\n",
    "                  )\n",
    "\n",
    "        # set bg colour\n",
    "        bg_colour = \"#FE9FA5\" # red\n",
    "        if normxcorr >= 0.85 and normxcorr < 0.9:\n",
    "            bg_colour = \"#FFB863\" # orange\n",
    "        if normxcorr >= 0.9 and normxcorr < 0.95:\n",
    "            bg_colour = \"#FFF263\" # yellow     \n",
    "        if normxcorr >= 0.95 and normxcorr < 0.99:\n",
    "            bg_colour = \"#96FEBF\" # green\n",
    "        elif normxcorr >= 0.99:\n",
    "            bg_colour = \"#8CDCFF\" # light blue\n",
    "        ax[i].set_facecolor(bg_colour)\n",
    "        ax[i].set_alpha(0.7)\n",
    "        plt.setp(ax[i].get_xticklabels(), fontsize=ticklabel_fontsize)\n",
    "        plt.setp(ax[i].get_yticklabels(), fontsize=ticklabel_fontsize)\n",
    "\n",
    "        # invert x-axis (ppm) to follow stupid NMR convention\n",
    "        xlim_ls = list(ax[i].get_xlim())\n",
    "        ax[i].set_xlim([max(xlim_ls), min(xlim_ls)])\n",
    "\n",
    "        # draw matching regions as gray bars\n",
    "        rect_height = ax[i].get_ylim()[1]\n",
    "        for row in matching_regions_ls:\n",
    "            # Create a rectangle patch\n",
    "            rect = patches.Rectangle((min(row), 0), \n",
    "                                     max(row) - min(row), \n",
    "                                     rect_height, \n",
    "                                     edgecolor=None,\n",
    "                                     facecolor='grey', \n",
    "                                     alpha=0.25)\n",
    "    \n",
    "            # Add the rectangle patch to the plot\n",
    "            ax[i].add_patch(rect)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # final bits\n",
    "    plt.subplots_adjust(hspace=0.2, wspace=0)\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "\n",
    "    i = StringIO()\n",
    "    fig.savefig(i, format=\"svg\")\n",
    "    output_svg = i.getvalue().strip().split(\"\\n\")\n",
    "    output_svg = \"\".join(output_svg)\n",
    "    svg_ls = resize_svg_bs4(output_svg, resize_coeff=0.5)\n",
    "    \n",
    "    # ===== prep html report =====\n",
    "    # not written as a function because of the sheer number of inputs required\n",
    "    html_contents = [\"<html><head></head><body>\"]\n",
    "    html_contents.append(\"<ul>\")\n",
    "    html_contents.append(f\"<li>Report generated: {datetime.today().strftime('%d %b %y, %-I:%M%p')}</li>\")\n",
    "    html_contents.append(f\"<li>num_samples = {len(results_dict)}</li>\")\n",
    "    html_contents.append(f\"<li>template = {template_path.split('/')[-1]}</li>\")\n",
    "    html_contents.append(f\"<li>normxcorr threshold = {normxcorr_th}</li>\")\n",
    "    html_contents.append(f\"<li>ref peak window = {ref_pk_window}</li>\")\n",
    "    html_contents.append(f\"<li>ref peak tolerance window = {ref_pk_tolerance_window}</li>\")\n",
    "    html_contents.append(f\"<li>search region padding size (ppm) = {search_region_padding_size}</li>\")\n",
    "    html_contents.append(\"</ul>\")\n",
    "\n",
    "    html_contents.append(\"<hr>\")\n",
    "    for line in output_svg:\n",
    "        html_contents.append(line)\n",
    "    html_contents.append(\"</body></html>\")\n",
    "\n",
    "    # ===== write out =====\n",
    "    # write out html\n",
    "    fn_out_plot = f\"batch{batch_num}_viz.html\"\n",
    "    with open(f\"./{folder_name}/{fn_out_plot}\", \"w\") as f:\n",
    "        for line in html_contents:\n",
    "            f.write(line)\n",
    "\n",
    "    # write out csvs\n",
    "    dz = pd.merge(d_concpred, df_conc, on=\"sample_name\")\n",
    "    dz.to_csv(os.path.join(folder_name, f\"batch{batch_num}_concpred.csv\"), index=False)\n",
    "    \n",
    "    batch_num += 1\n",
    "\n",
    "print(\"Done in %.2fs\" % (time.perf_counter() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get csv of results\n",
    "dz_rho = pd.concat(d_rho_ls, axis=0).reset_index(drop=True)\n",
    "dz_lr_results = pd.concat(d_lr_results_ls, axis=0).reset_index(drop=True)\n",
    "\n",
    "# merge\n",
    "dz = pd.merge(dz_rho, dz_lr_results, on=\"sample_name\")\n",
    "print(len(dz))\n",
    "\n",
    "# write out\n",
    "dz.to_csv(f\"{folder_name}/conc_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
