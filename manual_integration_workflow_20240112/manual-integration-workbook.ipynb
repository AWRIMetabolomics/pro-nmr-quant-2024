{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4b2ac5-4b9b-4477-82d5-38a45322322e",
   "metadata": {},
   "source": [
    "# Manual Integration Workbook\n",
    "\n",
    "* this workbook is run once for each sample.\n",
    "* change `path_samples` (cell 2) to wherever you unzipped the folder on your local machine\n",
    "* change `sample_name`, `m` and `c` parameters (gradient and intercept, respectively) in cell 5, then run cell 6 to check the visualization. Run cell 5 and 6 as many times as you like until you get a fit that you like, then run cell 7 (last cell) to calculate conc based on AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a78ee6-f723-48dd-92d2-f61121bb4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 50)\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/dteng/Documents/bin/nmr_utils/\")\n",
    "from nmr_targeted_utils import *\n",
    "from nmr_fitting_funcs import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83f26f-cd59-4849-af30-338ebedb1005",
   "metadata": {},
   "source": [
    "# Admin Section - Make `.pkl` File, `blue_m1_dict.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ddc4b-852a-4f56-9a17-17ba535af31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_m1_pkl_path = \"blue_m1_dict_20240219_v2.pkl\"\n",
    "path_samples = \"/Users/dteng/Documents/zdata/nmr/manual-processing-14feb2024_pkg/manual-processing-14feb2024_csvs\"\n",
    "multiplets_ls = [[1.9,2.15], [2.295, 2.403], [3.25, 3.5],[4.1, 4.2]]\n",
    "mcoords = multiplets_ls[1]\n",
    "ref_pk_window = [-0.2, 0.2]\n",
    "ref_pk_tolerance_window = [0,0]\n",
    "# value of search_region_padding_size doesn't really matter, \n",
    "# since manual integ will sort this out anyway\n",
    "search_region_padding_size = 0.01\n",
    "mcoords_xl = [min(mcoords)-search_region_padding_size, \n",
    "              max(mcoords)+search_region_padding_size]\n",
    "\n",
    "df_dict = {}\n",
    "for fn in os.listdir(path_samples):\n",
    "    if \".csv\" in fn:\n",
    "        k = fn.replace(\".csv\", \"\")\n",
    "        dt = pd.read_csv(os.path.join(path_samples, fn))\n",
    "        dt = adjust_to_ref_peak(dt, ref_pk_window, ref_pk_tolerance_window)\n",
    "        # save whole spectra\n",
    "        df_dict[k] = dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03696a-c417-4d2b-9bb8-e81f25df53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual sanity check of all blue M1s\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(df_dict), \n",
    "                       ncols=2, \n",
    "                       figsize=(8, 2*len(df_dict))\n",
    "                      )\n",
    "\n",
    "i = 0\n",
    "\n",
    "for k in sorted(list(df_dict.keys())):\n",
    "    # plot ref_pk\n",
    "    df = df_dict[k].copy()\n",
    "    dt = df.loc[(df[\"ppm\"]>min(ref_pk_window)) & (df[\"ppm\"]<max(ref_pk_window))].copy()\n",
    "    ax[i, 0].plot(dt.ppm.values, dt.intensity.values, c=\"steelblue\")\n",
    "    \n",
    "    # plot multiplet\n",
    "    df = df_dict[k].copy()\n",
    "    dt = df.loc[(df[\"ppm\"]>min(mcoords_xl)) & (df[\"ppm\"]<max(mcoords_xl))].copy()\n",
    "    ax[i,1].plot(dt.ppm.values, dt.intensity.values, c=\"steelblue\")\n",
    "    ax[i,1].set_title(k)\n",
    "    i += 1\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"blue_m1.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66696bbd-3ab9-4d68-adec-5e37e6626843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create blue_m1_dict\n",
    "blue_m1_dict = {}\n",
    "for k, dt in df_dict.items():\n",
    "    # save ref_pk\n",
    "    dt2 = dt.copy()\n",
    "    dt2 = dt2.loc[(dt2[\"ppm\"] > min(ref_pk_window)) & (dt2[\"ppm\"] < max(ref_pk_window))].copy()\n",
    "    temp_dict = {\"ref_pk\": dt2}\n",
    "    \n",
    "    # save multiplet1\n",
    "    dt2 = dt.copy()\n",
    "    dt2 = dt2.loc[(dt2[\"ppm\"] > min(mcoords_xl)) & (dt2[\"ppm\"] < max(mcoords_xl))].copy()\n",
    "    temp_dict[\"multiplet_1\"] = dt2\n",
    "    \n",
    "    # save\n",
    "    blue_m1_dict[k] = temp_dict\n",
    "\n",
    "# save as .pkl\n",
    "with open(blue_m1_pkl_path, 'wb') as f:\n",
    "    pickle.dump(blue_m1_dict, f)\n",
    "\n",
    "print(f\"Saved as {blue_m1_pkl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca6775-7c8f-4a9f-b79c-930bea3c8f2f",
   "metadata": {},
   "source": [
    "# User Section - Run, With `.pkl` File Already Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d22c6e4-8787-4e8e-aade-dc1049cbec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2\n",
    "\n",
    "# ===== params =====\n",
    "template_path = \"lproline_ph3.csv\"\n",
    "# change path_samples as required. Use the full path, which is easiest obtained from the topbar in Win Explorer\n",
    "path_samples = \"/Users/dteng/Documents/zdata/nmr/manual-processing-14feb2024_pkg/manual-processing-14feb2024_csvs\"\n",
    "bs_grad_path = \"bootstrap_results_12sep2023.csv\"\n",
    "blue_m1_pkl_path = \"blue_m1_dict_20240219_v2.pkl\"\n",
    "\n",
    "multiplets_ls = [[1.9,2.15], [2.295, 2.403], [3.25, 3.5],[4.1, 4.2]]\n",
    "ref_pk_window = [-0.2, 0.2]\n",
    "ref_pk_tolerance_window = [0,0]\n",
    "search_region_padding_size = 0.02\n",
    "\n",
    "# ========== load data ==========\n",
    "# load STD template(s)\n",
    "template_df = pd.read_csv(template_path)\n",
    "template_df = adjust_to_ref_peak(template_df, ref_pk_window, ref_pk_tolerance_window)\n",
    "\n",
    "# load blue_m1_dict\n",
    "with open(blue_m1_pkl_path, 'rb') as f:\n",
    "    blue_m1_dict = pickle.load(f)\n",
    "\n",
    "# load sample data\n",
    "# df_dict = {}\n",
    "# for fn in os.listdir(path_samples):\n",
    "#     if \".csv\" in fn:\n",
    "#         k = fn.replace(\".csv\", \"\")\n",
    "#         df_dict[k] = pd.read_csv(os.path.join(path_samples, fn))\n",
    "\n",
    "# load gradient data\n",
    "grad_df = pd.read_csv(bs_grad_path)\n",
    "\n",
    "# get reds\n",
    "red_dt = template_df.copy()\n",
    "red_dt = red_dt.loc[(red_dt[\"ppm\"]>min(multiplets_ls[1])) & (red_dt[\"ppm\"]<max(multiplets_ls[1]))]\n",
    "\n",
    "# print out list of sample names, to copy-paste into cell 5\n",
    "for k in sorted(list(df_dict.keys())):\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17285c81-bee1-4c1a-888a-aec7a0bfec58",
   "metadata": {},
   "source": [
    "### Toggle Constant And Coefficient\n",
    "\n",
    "Change gradient (`m`) and intercept (`c`) as needed, iterating until the blue (`sample`) and red (`std`) fit in the plot in the cell one after this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751a36a-9413-42b8-a36a-6587974e0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5\n",
    "\n",
    "# pick a sample\n",
    "sample_name = \"AF62827_Reacquire\"\n",
    "# gradient, change as required\n",
    "m = 0.4\n",
    "# intercept, change as required\n",
    "c = 1E6\n",
    "# x_shift applied to red, change as required\n",
    "x_shift = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b817896-99ca-46fa-9a2a-65b9f109f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6 - show plot\n",
    "\n",
    "blue_m1_dt = blue_m1_dict[sample_name].copy()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "\n",
    "ax[0].plot(blue_m1_dt[\"ref_pk\"].ppm.values, \n",
    "           blue_m1_dt[\"ref_pk\"].intensity.values, \n",
    "           c=\"steelblue\")\n",
    "ax[1].plot(blue_m1_dt[\"multiplet_1\"].ppm.values, \n",
    "           blue_m1_dt[\"multiplet_1\"].intensity.values, \n",
    "           c=\"steelblue\", \n",
    "           label=sample_name)\n",
    "ax[1].plot(red_dt.ppm.values+x_shift, (red_dt.intensity.values*m)+c, c=\"indianred\", label=\"std\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7efef-537d-43f4-99af-db8e2791a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7\n",
    "\n",
    "# print out AUC\n",
    "auc = np.sum(red_dt.intensity.values*m)+c\n",
    "print(auc)\n",
    "\n",
    "conc_ls = grad_df[\"V1\"].values * auc\n",
    "print(f\"conc: average = {np.average(conc_ls)}, sd = {np.std(conc_ls, ddof=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83195b38-fe40-49a9-b5f8-7fe0ad51839e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
