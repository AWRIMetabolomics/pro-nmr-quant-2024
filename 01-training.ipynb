{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step: Fit Calibration Function (Gradient)\n",
    "\n",
    "* Training Data: 33 unique sample IDs with to bootstrap a gradient with. Final output is a distro of gradients.\n",
    "* Fitting a gradient goes slightly beyond just doing it once with the training data: use bootstrapping to fit a histogram of gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import integrate\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from nmr_targeted_utils import *\n",
    "from nmr_fitting_funcs import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit results will be saved to folder: ./results/trg_fit-20241225_2021/\n",
      "Loaded 128 training samples.\n"
     ]
    }
   ],
   "source": [
    "# ===== params =====\n",
    "load_dotenv()\n",
    "\n",
    "path_samples = os.getenv(\"TRG_PATH\")\n",
    "template_path = \"./assets/lproline_ph3.csv\"\n",
    "#path_samples = \"/Users/dteng/Documents/zdata/nmr/J202208B_pro_survey/training_set_csvs/\"\n",
    "bs_grad_path = \"./results/bootstrap_results.csv\"\n",
    "\n",
    "# proline multiplet coords\n",
    "multiplets_ls = [[1.9,2.15], [2.295, 2.403], [3.25, 3.5],[4.1, 4.2]]\n",
    "\n",
    "normxcorr_th = 0.0 # set to this number to filter out multiplets which aren't at least normxcorr_th, i.e. poor fits\n",
    "ref_pk_window = [-0.2, 0.2]\n",
    "ref_pk_tolerance_window = [0,0]\n",
    "search_region_padding_size = 0.02\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "folder_name = f\"./results/trg_fit-{timestamp}\"\n",
    "fn_out_plot = \"training_fit_viz.html\"\n",
    "print(f\"fit results will be saved to folder: {folder_name}/\")\n",
    "\n",
    "# ========== load data ==========\n",
    "# load STD template(s)\n",
    "template_df = pd.read_csv(template_path)\n",
    "template_df = adjust_to_ref_peak(template_df, ref_pk_window, ref_pk_tolerance_window)\n",
    "\n",
    "# load sample (training) data - only QCs and Rs\n",
    "df_dict = {}\n",
    "for fn in os.listdir(path_samples):\n",
    "    if \".csv\" in fn:\n",
    "        k = fn.split(\".\")[0].replace(\"_QC\", \"_Q\")\n",
    "        df_dict[k] = pd.read_csv(os.path.join(path_samples, fn))\n",
    "print(f\"Loaded {len(df_dict)} training samples.\")\n",
    "\n",
    "# manually specify matching regions, that will be used for least-squares fitting later\n",
    "matching_regions_ls = [\n",
    "    [2.305, 2.306],\n",
    "    [2.31, 2.316],\n",
    "    [2.321, 2.3225],\n",
    "    [2.331, 2.333],\n",
    "    [2.337, 2.339],\n",
    "    [2.342, 2.3445],\n",
    "    [2.347, 2.349],\n",
    "    [2.3585, 2.3605],\n",
    "    [2.365, 2.3675],\n",
    "    [2.3755, 2.3765],\n",
    "    [2.381, 2.39]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: shifting blues instead of reds in get_blue_m1_dict().\n"
     ]
    }
   ],
   "source": [
    "# ===== run 1d_std_search =====\n",
    "results_dict = {}\n",
    "for k in sorted(list(df_dict.keys())):\n",
    "    target_df = df_dict[k]\n",
    "    results_dict[k] = do_1d_std_search(\n",
    "        query_df=template_df,\n",
    "        target_df=target_df,\n",
    "        multiplets_ls=multiplets_ls,\n",
    "        search_region_padding_size=search_region_padding_size\n",
    "    )\n",
    "\n",
    "# get reds\n",
    "red_dt = template_df.copy()\n",
    "red_dt = red_dt.loc[(red_dt[\"ppm\"]>min(multiplets_ls[1])) & (red_dt[\"ppm\"]<max(multiplets_ls[1]))]\n",
    "\n",
    "# get blues\n",
    "blue_m1_dict = get_blue_m1_dict(results_dict, \n",
    "                                df_dict,\n",
    "                                mcoords=multiplets_ls[1]\n",
    "                               )\n",
    "\n",
    "# ===== get corr_series_dict =====\n",
    "# get corr_series for each k, stored in corr_series_dict\n",
    "corr_series_dict = {}\n",
    "for k in sorted(list(results_dict.keys())):\n",
    "    dt = get_correlation_series(red_dt, \n",
    "                                blue_m1_dict[k].copy(),\n",
    "                                min_corr=0, \n",
    "                                min_corr_replacement_value=0,\n",
    "                                window_size_nrows=64,\n",
    "                                exponent=8\n",
    "                               )\n",
    "    corr_series_dict[k] = dt\n",
    "\n",
    "# ===== run LR matching =====\n",
    "df_conc = get_df_conc_lrmatching(\n",
    "    results_dict=results_dict, \n",
    "    template_df=template_df.copy(), \n",
    "    df_dict=df_dict, \n",
    "    mcoords=multiplets_ls[1],\n",
    "    matching_coords_ls=matching_regions_ls,\n",
    "    corr_series_dict=corr_series_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz Fit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 13.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote out to: ./results/trg_fit-20241225_2021/training_fit_viz.html\n"
     ]
    }
   ],
   "source": [
    "# plot multiplet_1 only\n",
    "t0 = time.time()\n",
    "\n",
    "# ===== plot match results =====\n",
    "fig, ax = plt.subplots(nrows=len(results_dict), # top row for LR results\n",
    "                       ncols=1, \n",
    "                       figsize=(7, len(results_dict)*4)\n",
    "                      )\n",
    "\n",
    "red_dt = template_df.copy()\n",
    "red_dt = red_dt.loc[(red_dt[\"ppm\"]>min(multiplets_ls[1])) & (red_dt[\"ppm\"]<max(multiplets_ls[1]))]\n",
    "\n",
    "i = 0\n",
    "for k in sorted(list(results_dict.keys())):\n",
    "    # plot fit\n",
    "    normxcorr = results_dict[k][\"multiplet_1\"][\"max_rho\"][0]\n",
    "    ax[i].plot(blue_m1_dict[k].ppm.values, \n",
    "               blue_m1_dict[k].intensity.values, c=\"steelblue\")\n",
    "\n",
    "    m = df_conc.loc[df_conc[\"sample_name\"]==k][\"slope\"].values[0]\n",
    "    c = df_conc.loc[df_conc[\"sample_name\"]==k][\"intercept\"].values[0]\n",
    "    ax[i].plot(red_dt.ppm.values, \n",
    "               (red_dt.intensity.values*m)+c, \n",
    "               c=\"indianred\")\n",
    "\n",
    "    ax[i].set_title(f\"{i+1}. {k}\\nnormxcorr={round(normxcorr, 4)}\", fontsize=20)\n",
    "    \n",
    "    # plot sliding window of correlation\n",
    "    ax2 = ax[i].twinx()\n",
    "    ax2.plot(corr_series_dict[k][\"ppm\"], \n",
    "             corr_series_dict[k][\"corr_series\"], \n",
    "             lw=0.7,\n",
    "             c=\"k\")\n",
    "    \n",
    "    # set bg colour\n",
    "    transparency = 0.65\n",
    "    bg_colour = (1, 159/255, 165/255, transparency) # red\n",
    "    if normxcorr >= 0.85 and normxcorr < 0.9:\n",
    "        bg_colour = (1, 184/255, 100/255, transparency) # orange\n",
    "    if normxcorr >= 0.9 and normxcorr < 0.95:\n",
    "        bg_colour = (1, 242/255, 100/255, transparency) # yellow     \n",
    "    if normxcorr >= 0.95 and normxcorr < 0.99:\n",
    "        bg_colour = (150/255, 1, 153/255, transparency) # green\n",
    "    elif normxcorr >= 0.99:\n",
    "        bg_colour = (140/255, 220/255, 1, transparency) # light blue\n",
    "    ax[i].set_facecolor(bg_colour)\n",
    "    plt.setp(ax[i].get_xticklabels(), fontsize=20)\n",
    "    plt.setp(ax[i].get_yticklabels(), fontsize=20)\n",
    "    \n",
    "    # draw matching regions\n",
    "    rect_height = ax[i].get_ylim()[1]\n",
    "    for row in matching_regions_ls:\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((min(row), 0), \n",
    "                                 max(row) - min(row), \n",
    "                                 rect_height, \n",
    "                                 edgecolor=None,\n",
    "                                 facecolor='grey', \n",
    "                                 alpha=0.25)\n",
    "\n",
    "        # Add the rectangle patch to the plot\n",
    "        ax[i].add_patch(rect)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.subplots_adjust(hspace=0.2, wspace=0)\n",
    "plt.tight_layout()\n",
    "plt.close()\n",
    "\n",
    "print(\"Done in %.2fs\" % (time.time() - t0))\n",
    "\n",
    "i = StringIO()\n",
    "fig.savefig(i, format=\"svg\")\n",
    "output_svg = i.getvalue().strip().split(\"\\n\")\n",
    "output_svg = \"\".join(output_svg)\n",
    "svg_ls = resize_svg_bs4(output_svg, resize_coeff=0.65)\n",
    "\n",
    "# ===== prep html report =====\n",
    "# not written as a function because of the sheer number of inputs required\n",
    "html_contents = [\"<html><head></head><body>\"]\n",
    "\n",
    "html_contents.append(\"<ul>\")\n",
    "html_contents.append(f\"<li>Report generated: {datetime.today().strftime('%d %b %y, %-I:%M%p')}</li>\")\n",
    "html_contents.append(f\"<li>num_samples = {len(results_dict)}</li>\")\n",
    "html_contents.append(f\"<li>template = {template_path.split('/')[-1]}</li>\")\n",
    "html_contents.append(f\"<li>normxcorr threshold = {normxcorr_th}</li>\")\n",
    "html_contents.append(f\"<li>ref peak window = {ref_pk_window}</li>\")\n",
    "html_contents.append(f\"<li>ref peak tolerance window = {ref_pk_tolerance_window}</li>\")\n",
    "html_contents.append(f\"<li>search region padding size (ppm) = {search_region_padding_size}</li>\")\n",
    "#html_contents.append(f\"<li>Output csv = {fn_out_df}</li>\")\n",
    "html_contents.append(\"</ul>\")\n",
    "\n",
    "html_contents.append(\"<hr>\")\n",
    "for line in output_svg:\n",
    "    html_contents.append(line)\n",
    "html_contents.append(\"</body></html>\")\n",
    "\n",
    "# ===== write out =====\n",
    "# make foldername\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "with open(f\"./{folder_name}/{fn_out_plot}\", \"w\") as f:\n",
    "    for line in html_contents:\n",
    "        f.write(line)\n",
    "\n",
    "print(f\"Wrote out to: {folder_name}/{fn_out_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== write out csv =====\n",
    "# write out a formatted csv as input to bootstrapping.R\n",
    "d0 = df_conc.copy()\n",
    "af_id_q_ls = []\n",
    "af_id_r_ls = []\n",
    "for nm in d0[\"sample_name\"].values:\n",
    "    if (\"_Q1\" in nm) or (\"_Q2\" in nm):\n",
    "        af_id_q_ls.append(nm)\n",
    "        r_name = nm.replace(\"_Q1\", \"_R1\").replace(\"_Q2\", \"_R2\")\n",
    "        af_id_r_ls.append(r_name)\n",
    "\n",
    "d0_q = d0.loc[d0[\"sample_name\"].isin(af_id_q_ls)].reset_index(drop=True)[['sample_name', 'auc']]\n",
    "d0_r = d0.loc[d0[\"sample_name\"].isin(af_id_r_ls)].reset_index(drop=True)[['sample_name', 'auc']]\n",
    "d0_q.columns = [\"sample_name_q\", \"auc_q\"]\n",
    "d0_r.columns = [\"sample_name_r\", \"auc_r\"]\n",
    "\n",
    "dz = pd.concat([d0_q, d0_r], axis=1)\n",
    "\n",
    "# write out\n",
    "dz.to_csv(f\"{folder_name}/df_conc_t.csv\", index=False)\n",
    "print(\"Wrote out df_conc_t.csv as a formatted input to bootstrapping.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Estimate Distribution of Gradient\n",
    "\n",
    "* Bootstrapping = \"out of a population of size m, repeatedly take sample of size n with replacement.\"\n",
    "* Run the bootstrapping cell (indicated by a comment \"#bootstrapping cell\" in the first line) iteratively in this workbook to get a rough idea of \"start\" and \"end\", for bootstrapping bounds. The bootstrapping cell is run with only a few (10 or 100) bootstrap samples (or `num_iter`). After that, plot a histogram of gradients in the cell after. Make sure that this histogram contains a maxima. If it doesn't, it means that your choice of start and end need to be shifted until `start` and `end` enclose a maxima.\n",
    "* You can do a bootstrapping run in this notebook if you're willing to wait a few hours (just increase `num_iter` to a very high number like 5000), or you can run `bootstrapping.R` (that uses parallel processing) in a cloud VM of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling cell to wrangle data into a format to use in the next cell\n",
    "d0 = df_conc.copy()\n",
    "\n",
    "# get list of unique AF IDs\n",
    "temp_ls = list(set([x.replace(\"_Q1\", \"\").replace(\"_Q2\", \"\").replace(\"_R1\", \"\").replace(\"_R2\", \"\") for x in d0[\"sample_name\"].values]))\n",
    "\n",
    "uq_af_id_ls = []\n",
    "outliers_ls = [\"AWAC105\", \"AF63412\"] # manually exclude known outliers\n",
    "for af_id in temp_ls:\n",
    "    if af_id not in outliers_ls:\n",
    "        uq_af_id_ls.append(af_id)\n",
    "\n",
    "# Get name pairs for each AF ID\n",
    "af_id_namepair_ls = []\n",
    "af_id_q_ls = []\n",
    "af_id_r_ls = []\n",
    "for af_id in uq_af_id_ls:\n",
    "    k = af_id+\"_Q1\"\n",
    "    val = af_id+\"_R1\"\n",
    "    af_id_namepair_ls.append([k, val])\n",
    "    k = af_id+\"_Q2\"\n",
    "    val = af_id+\"_R2\"\n",
    "    af_id_namepair_ls.append([k, val])\n",
    "    \n",
    "    af_id_q_ls.append(af_id+\"_Q1\")\n",
    "    af_id_q_ls.append(af_id+\"_Q2\")\n",
    "    \n",
    "    af_id_r_ls.append(af_id+\"_R1\")\n",
    "    af_id_r_ls.append(af_id+\"_R2\")\n",
    "\n",
    "af_id_namepair_ls = np.array(af_id_namepair_ls)\n",
    "d0_q = d0.loc[d0[\"sample_name\"].isin(af_id_q_ls)].copy()[[\"sample_name\", \"auc\"]]\n",
    "d0_r = d0.loc[d0[\"sample_name\"].isin(af_id_r_ls)].copy()[[\"sample_name\", \"auc\"]]\n",
    "m_q = d0_q.values\n",
    "m_r = d0_r.values\n",
    "\n",
    "# sanity check: m_q and r_q must have the same Q and R AF_IDs in each row\n",
    "# there will be no 'ERROR...' printout if all clear\n",
    "for i in range(len(m_q)):\n",
    "    afid_q = m_q[i][0].replace(\"_Q1\", \"\").replace(\"_Q2\", \"\")\n",
    "    afid_r = m_r[i][0].replace(\"_R1\", \"\").replace(\"_R2\", \"\")\n",
    "    if afid_q != afid_r:\n",
    "        print(f\"ERROR: AF IDs not the same in row {i}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 36.24s\n"
     ]
    }
   ],
   "source": [
    "#bootstrapping cell\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "end = 1.3E-9\n",
    "start = 1.26E-9\n",
    "grad_ls = get_sf_range(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    iter_size=1E-15 #interval_width\n",
    ")\n",
    "\n",
    "# start at 10 or 100 to estimate time taken, increase if you feel like it\n",
    "# best to increase until you see a nice bell-shape in the histogram below\n",
    "num_bootstrap_samples = 100\n",
    "\n",
    "mse_ls_ls = []\n",
    "best_grad_ls = []\n",
    "for i in range(num_bootstrap_samples):\n",
    "    bootstrap_idx_ls = np.random.choice(np.arange(len(af_id_namepair_ls)), \n",
    "                                    size=len(af_id_namepair_ls), \n",
    "                                    replace=True\n",
    "                                   )\n",
    "    bootstrap_samples_ls = af_id_namepair_ls[bootstrap_idx_ls]\n",
    "    \n",
    "    auc_q_ls = d0.loc[d0[\"sample_name\"].isin(bootstrap_samples_ls[:, 0])][\"auc\"].values\n",
    "    auc_r_ls = d0.loc[d0[\"sample_name\"].isin(bootstrap_samples_ls[:, 1])][\"auc\"].values\n",
    "    \n",
    "    mse_ls = []\n",
    "    for grad in grad_ls:\n",
    "        # this is a matrix operation, maybe np.matmul faster?\n",
    "        err_ls = (grad*auc_q_ls) - (grad*auc_r_ls) - 1115\n",
    "        mse = np.sum(np.square(err_ls))\n",
    "        mse_ls.append(mse)\n",
    "\n",
    "    best_grad = grad_ls[np.argmin(mse_ls)]\n",
    "    #mse_ls_ls.append(mse_ls)\n",
    "    best_grad_ls.append(best_grad)\n",
    "\n",
    "ave_best_grad = np.average(best_grad_ls)\n",
    "\n",
    "print(\"Done in %.2fs\" % (time.perf_counter() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2791307100000004e-09\n"
     ]
    }
   ],
   "source": [
    "plt.hist(best_grad_ls, bins=50)\n",
    "\n",
    "plt.show()\n",
    "print(np.average(best_grad_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "dt = pd.DataFrame(data=best_grad_ls, columns=[\"grad_val\"])\n",
    "dt.to_csv(\"./results/bootstrap_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
